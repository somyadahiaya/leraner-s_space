{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "c985c9a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/somyadahiaya/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "80d3d813",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =pd.read_csv(\"reviews_100.csv\")\n",
    "# df =pd.read_csv(\"IMDB Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "25179071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative    50\n",
      "positive    50\n",
      "Name: sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "cc1d2ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The movie was <br>BLOCKBUSTER!!!! <br>\n",
      "movie blockbuster!!!!\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def cleanup(text):\n",
    "    text =re.sub(r'<[^>]+>', '', text)\n",
    "    text= [word.lower() for word in text.split() if word.lower() not in stop_words]\n",
    "    text=' '.join(text)\n",
    "    return text\n",
    "\n",
    "print(\"The movie was <br>BLOCKBUSTER!!!! <br>\")\n",
    "print(cleanup(\"The movie was BLOCKBUSTER!!!!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "c5e2ce40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned']=df['review'].apply(cleanup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "b01ef9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=300,ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "de8d9a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorised= vectorizer.fit_transform(df['cleaned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "fc67d88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 243)\t0.15274579000749217\n",
      "  (0, 256)\t0.13177124016929537\n",
      "  (0, 158)\t0.10528435385239325\n",
      "  (0, 214)\t0.14310570721999583\n",
      "  (0, 171)\t0.060932263635392774\n",
      "  (0, 257)\t0.08430980401419645\n",
      "  (0, 245)\t0.13177124016929537\n",
      "  (0, 178)\t0.2105687077047865\n",
      "  (0, 102)\t0.13522918606987727\n",
      "  (0, 254)\t0.11316087500251182\n",
      "  (0, 133)\t0.13898818727199122\n",
      "  (0, 46)\t0.13522918606987727\n",
      "  (0, 100)\t0.12856968232651733\n",
      "  (0, 139)\t0.25713936465303466\n",
      "  (0, 143)\t0.11537680999784197\n",
      "  (0, 190)\t0.14310570721999583\n",
      "  (0, 40)\t0.10528435385239325\n",
      "  (0, 126)\t0.16517401828736128\n",
      "  (0, 280)\t0.09862485010903331\n",
      "  (0, 89)\t0.13898818727199122\n",
      "  (0, 222)\t0.15274579000749217\n",
      "  (0, 25)\t0.23542516426452476\n",
      "  (0, 72)\t0.10182640795181135\n",
      "  (0, 282)\t0.3461010788749597\n",
      "  (0, 31)\t0.23075361999568395\n",
      "  :\t:\n",
      "  (98, 143)\t0.08589061585891852\n",
      "  (98, 25)\t0.08762944801362293\n",
      "  (98, 72)\t0.07580321288000716\n",
      "  (98, 141)\t0.10066943325837567\n",
      "  (98, 87)\t0.14458260483197002\n",
      "  (99, 263)\t0.3512088091878791\n",
      "  (99, 35)\t0.648465467024084\n",
      "  (99, 164)\t0.16357677027468828\n",
      "  (99, 69)\t0.4323103113493893\n",
      "  (99, 226)\t0.14597786353571363\n",
      "  (99, 34)\t0.1424311368503284\n",
      "  (99, 200)\t0.1109983848746819\n",
      "  (99, 116)\t0.14980862018747237\n",
      "  (99, 267)\t0.13912921330158323\n",
      "  (99, 67)\t0.13313904184984202\n",
      "  (99, 103)\t0.1109983848746819\n",
      "  (99, 138)\t0.11867220915160842\n",
      "  (99, 101)\t0.0959189497788357\n",
      "  (99, 32)\t0.13313904184984202\n",
      "  (99, 37)\t0.13313904184984202\n",
      "  (99, 71)\t0.1059559455579721\n",
      "  (99, 216)\t0.11280459579210249\n",
      "  (99, 171)\t0.06750154020301999\n",
      "  (99, 143)\t0.12781590431578466\n",
      "  (99, 221)\t0.11468165632847822\n"
     ]
    }
   ],
   "source": [
    "print(vectorised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "f20ba697",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=vectorised.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cc5ac7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "15382c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 300)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "df['label'] = df['sentiment'].map({'positive': 1, 'negative': 0})\n",
    "y=df['label']\n",
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "87aa1978",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,stratify=y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "160e4f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model= LogisticRegression(class_weight='balanced')\n",
    "model.fit(X_train,y_train)\n",
    "y_pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6742d2db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "bd9b1edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.90      0.75        10\n",
      "           1       0.83      0.50      0.62        10\n",
      "\n",
      "    accuracy                           0.70        20\n",
      "   macro avg       0.74      0.70      0.69        20\n",
      "weighted avg       0.74      0.70      0.69        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "26776ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocess_vectorize(texts, vectorizer):\n",
    "    cleaned=[]\n",
    "    for text in texts:\n",
    "        cleaned.append(cleanup(text))\n",
    "    vectorised=vectorizer.transform(cleaned)\n",
    "    return vectorised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "0d8af83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    label  testing\n",
      "0       0        0\n",
      "1       0        0\n",
      "2       0        0\n",
      "3       1        1\n",
      "4       1        1\n",
      "..    ...      ...\n",
      "95      0        0\n",
      "96      0        0\n",
      "97      1        1\n",
      "98      0        0\n",
      "99      0        1\n",
      "\n",
      "[100 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "sample=text_preprocess_vectorize(df['review'],vectorizer)\n",
    "results=model.predict(sample.toarray())\n",
    "\n",
    "df['testing']=results\n",
    "\n",
    "print(df[['label','testing']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "51868a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An absolutely stunning movie with a powerful message! ----> 1\n",
      "Absolutely amazing work, good movie. ----> 1\n",
      "Worst movie ever, not recommended ----> 0\n",
      "good movie , thriller and intersting to watch with friends. ----> 1\n"
     ]
    }
   ],
   "source": [
    "review_texts = [\"An absolutely stunning movie with a powerful message!\",\"Absolutely amazing work, good movie.\", \"Worst movie ever, not recommended\", \"good movie , thriller and intersting to watch with friends.\" ]\n",
    "\n",
    "sample=text_preprocess_vectorize(review_texts,vectorizer)\n",
    "\n",
    "\n",
    "\n",
    "results=model.predict(sample.toarray())\n",
    "\n",
    "for i in  range(0,len(review_texts)):\n",
    "    print(review_texts[i],\"---->\",results[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffe9db2",
   "metadata": {},
   "source": [
    "When we use 300 features and dataset size of 100 , the accuracy is 0.7, while if we increase the dataset size to the actual data, the accuracy becomes 0.81. I have used ngram in my tfidf vectoriser to also take the account of word combinations such as \"not good\" or \"very good\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
